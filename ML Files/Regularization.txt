import numpy as np

# Data
X = np.array([1, 2, 3, 4, 5])
y = np.array([3, 4, 2, 4, 5])

# Initialize parameters
w = 0.0  # initial weight
b = 0.0  # initial bias
learning_rate = 0.01
lambda_reg = 0.1  # regularization strength
epochs = 1000  # number of iterations
n = len(X)  # number of data points

# Gradient descent
for epoch in range(epochs):
    # Predicted values
    y_pred = w * X + b
    
    # Gradients
    dw = (-2 / n) * np.sum(X * (y - y_pred)) + 2 * lambda_reg * w
    db = (-2 / n) * np.sum(y - y_pred)
    
    # Update weights and bias
    w -= learning_rate * dw
    b -= learning_rate * db

# Final predictions
y_final_pred = w * X + b

# Results
print(f"Final weight (w): {w:.4f}")
print(f"Final bias (b): {b:.4f}")
print(f"Final predictions: {y_final_pred}")


