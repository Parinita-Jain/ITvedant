{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e06463-9b9f-4cf6-81c8-75b9991421bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "on the jupyter notebook launch terminal install--\n",
    "pip install mediapipe opencv-python numpy\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fb37b02-12c5-4a46-a027-ef35f7a4baba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¥ Press 'q' to exit the video window.\n",
      "âœ… Video processing complete and window closed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time # time: Can be used for FPS calculations (not used in this version).\n",
    "\n",
    "# Load MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=False, \n",
    "    max_num_faces=2, \n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "'''\n",
    "mp_face_mesh.FaceMesh(...): Creates a face mesh model with:\n",
    "static_image_mode=False: Optimized for video (tracking instead of detecting each frame separately).\n",
    "max_num_faces=2: Detect up to 2 faces at a time.\n",
    "min_detection_confidence=0.5: 50% confidence threshold to detect a face.\n",
    "min_tracking_confidence=0.5: 50% confidence threshold to track landmarks.\n",
    "mp_draw = mp.solutions.drawing_utils: Loads functions to draw face landmarks.\n",
    "\n",
    "'''\n",
    "'''\n",
    "# Load video file\n",
    "video_path = \"video.mp4\"  # Replace with your video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "'''\n",
    "cap = cv2.VideoCapture(0) \n",
    "# Check if video file is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    cap.release()\n",
    "else:\n",
    "    # Get video properties\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    '''\n",
    "    Gets the videoâ€™s width, height, and FPS.\n",
    "    Creates a VideoWriter object (out) to save the processed video.\n",
    "    '''\n",
    "\n",
    "    # Define video writer to save output\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(\"output.mp4\", fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    print(\"Press 'q' to exit the video window.\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Exit loop when video ends\n",
    "\n",
    "        # Convert BGR to RGB\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process frame with Face Mesh\n",
    "        results = face_mesh.process(rgb_frame)\n",
    "        '''\n",
    "        Reads a frame from the video (cap.read()).\n",
    "        If the frame is empty (end of video), it exits the loop.\n",
    "        Converts the BGR frame to RGB (because MediaPipe uses RGB).\n",
    "        Processes the frame to detect face mesh landmarks.\n",
    "        '''\n",
    "\n",
    "        # Draw landmarks if face is detected\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                mp_draw.draw_landmarks(\n",
    "                    frame, face_landmarks, mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                    mp_draw.DrawingSpec(color=(0, 255, 0), thickness=1, circle_radius=1),\n",
    "                    mp_draw.DrawingSpec(color=(255, 255, 255), thickness=1)\n",
    "                )\n",
    "        '''\n",
    "        Checks if any face was detected (if results.multi_face_landmarks:).\n",
    "        Loops through all detected faces.\n",
    "        Draws landmarks on the face, connecting 468 key points.\n",
    "        Green dots (circle_radius=1) for keypoints and white lines (thickness=1) for connections.\n",
    "        '''\n",
    "\n",
    "        # Show the frame in a separate OpenCV window\n",
    "        cv2.imshow(\"Face Mesh Output\", frame)\n",
    "\n",
    "        # Press 'q' to exit the video window\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Write processed frame to output file\n",
    "        out.write(frame)\n",
    "        '''\n",
    "        Displays the processed frame in a separate OpenCV window.\n",
    "        Waits for keypress ('q') to exit (cv2.waitKey(1) & 0xFF == ord('q')).\n",
    "        Writes the processed frame to \"output.mp4\".\n",
    "\n",
    "        '''\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Video processing complete and window closed.\")\n",
    "\n",
    "'''\n",
    "Releases the video and output file resources.\n",
    "Closes the OpenCV window (cv2.destroyAllWindows()).\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6edba40-c247-413b-b118-888ff3cd6ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ee77d2-0aab-4040-ae82-e0e4db014afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the models\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "holistic_model = mp_holistic.Holistic()\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76daefe3-6772-4ec9-8559-eae58012e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture the video\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "# For calculation of Frame Per Second (FPS)\n",
    "\n",
    "previousTime = 0\n",
    "currentTime = 0\n",
    "\n",
    "while capture.isOpened():\n",
    "\n",
    "    # Capture the frame\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    # Resize the frame\n",
    "    frame = cv2.resize(frame, (800,600))\n",
    "\n",
    "    # Convert from BGR to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect Landmarks\n",
    "    image.flags.writeable = False\n",
    "    results = holistic_model.process(image)\n",
    "    image.flags.writeable = True\n",
    "\n",
    "    # Convert back to BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Drawing Facial Landmarks\n",
    "\n",
    "    mp_drawing.draw_landmarks(\n",
    "    image, results.face_landmarks,\n",
    "    mp_holistic.FACEMESH_CONTOURS,\n",
    "    mp_drawing.DrawingSpec(\n",
    "    color = (255, 0, 255),\n",
    "    thickness = 1,\n",
    "    circle_radius = 1),\n",
    "    mp_drawing.DrawingSpec(\n",
    "    color = (255,0,255),\n",
    "    thickness=1,\n",
    "    circle_radius=1))\n",
    "\n",
    "    # Drawing Right Hand Landmarks\n",
    "\n",
    "    mp_drawing.draw_landmarks(\n",
    "    image, results.right_hand_landmarks,\n",
    "    mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "    # Drawing Left Hand Landmarks\n",
    "\n",
    "    mp_drawing.draw_landmarks(\n",
    "    image, results.left_hand_landmarks,\n",
    "    mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "    # Calculate the FPS\n",
    "    currentTime = time.time()\n",
    "    fps = 1/(currentTime-previousTime)\n",
    "    previousTime = currentTime\n",
    "\n",
    "    # Displaying FPS on the image\n",
    "\n",
    "    cv2.putText(image,\n",
    "                str(int(fps))+\" FPS\",\n",
    "                (10,70),\n",
    "                cv2.FONT_HERSHEY_COMPLEX,\n",
    "                1, (0, 255, 0),\n",
    "                2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('Mediapipe Practical', image)\n",
    "    key = cv2.waitKey(5)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e953668-2331-4443-8d9e-35581133d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pose Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ebf46-6a10-456c-b55f-8a15890d59fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a59ae50-b070-427d-9ff0-4d5d6ba2d402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1bc065-ac2f-4147-88fd-868466c935e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
