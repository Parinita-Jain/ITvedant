import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

# Activation Functions in NumPy
x = np.linspace(-5, 5, 100)
relu = np.maximum(0, x)
leaky_relu = np.where(x > 0, x, 0.01*x)
sigmoid = 1 / (1 + np.exp(-x))
tanh = np.tanh(x)

# Plot Activation Functions
plt.figure(figsize=(12, 6))

plt.subplot(2, 2, 1)
plt.plot(x, relu, label="ReLU")
plt.title("ReLU Activation Function")

plt.subplot(2, 2, 2)
plt.plot(x, leaky_relu, label="Leaky ReLU", color="orange")
plt.title("Leaky ReLU Activation Function")

plt.subplot(2, 2, 3)
plt.plot(x, sigmoid, label="Sigmoid", color="green")
plt.title("Sigmoid Activation Function")

plt.subplot(2, 2, 4)
plt.plot(x, tanh, label="Tanh", color="red")
plt.title("Tanh Activation Function")

plt.show()

